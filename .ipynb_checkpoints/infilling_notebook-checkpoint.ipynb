{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pytorch_metric_learning import losses\n",
    "from skimage import io, transform\n",
    "import time\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "# Device\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Num epochs\n",
    "num_epochs = 25\n",
    "\n",
    "# Model \n",
    "model = models.resnet18()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Data set\n",
    "train_path = '/lab/vislab/DATA/CUB/images/'\n",
    "\n",
    "# Loss function\n",
    "criterion = losses.TripletMarginLoss(margin=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "dataset = datasets.ImageFolder(train_path, transformations)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=None, num_workers=4)\n",
    "\n",
    "# dataset_size = len(dataset)\n",
    "# indices = list(range(dataset_size))\n",
    "# split = int(np.floor(.4 * dataset_size))\n",
    "# np.random.seed(32)\n",
    "# np.random.shuffle(indices)\n",
    "# train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "\n",
    "# test_split = int(np.floor(.1 * dataset_size))\n",
    "# np.random.seed(32)\n",
    "# np.random.shuffle(val_indices)\n",
    "# val_indices, test_indices = val_indices[test_split:], val_indices[:test_split]\n",
    "\n",
    "# # Creating PT data samplers and loaders:\n",
    "# train_sampler = SubsetRandomSampler(train_indices)\n",
    "# valid_sampler = SubsetRandomSampler(val_indices)\n",
    "# test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "#                                            sampler=train_sampler, num_workers=4)\n",
    "# validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "#                                                 sampler=valid_sampler)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "#                                                 sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def map_features(outputs, labels, out_file):\n",
    "    # create array of column for each feature output\n",
    "    feat_cols = ['feature'+str(i) for i in range(outputs.shape[1])]\n",
    "    # make dataframe of outputs -> labels\n",
    "    df = pd.DataFrame(outputs, columns=feat_cols)\n",
    "    df['y'] = labels\n",
    "    df['labels'] = df['y'].apply(lambda i: str(i))\n",
    "    # clear outputs and labels\n",
    "    outputs, labels = None, None\n",
    "    # creates an array of random indices from size of outputs\n",
    "    np.random.seed(42)\n",
    "    rndperm = np.random.permutation(df.shape[0])\n",
    "    num_examples = 3000\n",
    "    df_subset = df.loc[rndperm[:num_examples],:].copy()\n",
    "    data_subset = df_subset[feat_cols].values\n",
    "    pca = PCA(n_components=50)\n",
    "    pca_result = pca.fit_transform(data_subset)\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "    tsne_results = tsne.fit_transform(data_subset)\n",
    "    df_subset['tsne-2d-one'] = tsne_results[:,0]\n",
    "    df_subset['tsne-2d-two'] = tsne_results[:,1]\n",
    "    plt.figure(figsize=(16,10))\n",
    "    plt.scatter(\n",
    "        x=df_subset[\"tsne-2d-one\"],\n",
    "        y=df_subset[\"tsne-2d-two\"],\n",
    "        c=df_subset[\"y\"],\n",
    "        s=3\n",
    "    )\n",
    "    plt.savefig(out_file, bbox_inches='tight', pad_inches = 0)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "def train_model():\n",
    "    \"\"\"Generic function to train model\"\"\"\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    correct = 0 \n",
    "    incorrect = 0 \n",
    "    num_batches = 0\n",
    "\n",
    "    # Epochs \n",
    "    for epoch in range(num_epochs): \n",
    "        print(\"epoch num:\", epoch)\n",
    "        running_outputs = torch.FloatTensor().cpu()\n",
    "        running_labels = torch.LongTensor().cpu()\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        \n",
    "        # Batches\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader): \n",
    "            num_batches += 1\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            output = model.forward(inputs)\n",
    "            \n",
    "            running_outputs = torch.cat((running_outputs, output.cpu().detach()), 0)\n",
    "            running_labels = torch.cat((running_labels, labels.cpu().detach()), 0)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            loss = Variable(loss, requires_grad = True)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Accuracy\n",
    "        for idx, emb in enumerate(running_outputs.to(device)):    \n",
    "            pairwise = torch.nn.PairwiseDistance(p=2).to(device)\n",
    "            dist = pairwise(emb, running_outputs.to(device))\n",
    "            closest = torch.topk(dist, 2, largest=False).indices[1]\n",
    "            if running_labels[idx] == running_labels[closest]:\n",
    "                correct += 1\n",
    "            else:\n",
    "                incorrect += 1\n",
    "\n",
    "        running_outputs = torch.cat((running_outputs, output.cpu().detach()), 0)\n",
    "        running_labels = torch.cat((running_labels, labels.cpu().detach()), 0)\n",
    "\n",
    "        print(running_outputs.shape)\n",
    "        print(running_labels.shape)\n",
    "        print(running_loss / num_batches)\n",
    "        print(\"correct\", correct)\n",
    "        print(\"incorrect\", incorrect)\n",
    "\n",
    "        # TSNE\n",
    "        map_features(running_outputs, running_labels, \"outfile\")\n",
    "        \n",
    "        time_elapsed = datetime.now() - start_time \n",
    "        print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))    \n",
    "\n",
    "    return model, running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    trained_model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        j = 0\n",
    "        corrects = 0\n",
    "        pairs = []\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = trained_model(data)\n",
    "            \n",
    "            print(output.shape)\n",
    "            break\n",
    "            \n",
    "            # do we do any test loss\n",
    "#             test_loss =  criterion(dista, distb, target).data.item()\n",
    "\n",
    "            for row in output: \n",
    "                distance_matrix = accuracy(row)\n",
    "                pairs.append(distance_matrix)\n",
    "                print(pairs[0])\n",
    "            d = distance_matrix.cpu().numpy()\n",
    "            print(type(d))\n",
    "            print(d.shape)\n",
    "            \n",
    "            print(min(d))\n",
    "\n",
    "            \n",
    "            # update losses? or no?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch num: 0\n",
      "torch.Size([6050, 1000])\n",
      "torch.Size([6050])\n",
      "0.13050219353544648\n",
      "correct 418\n",
      "incorrect 5615\n",
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 3000 samples in 0.068s...\n",
      "[t-SNE] Computed neighbors for 3000 samples in 14.099s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 3000\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 3000\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 3000\n",
      "[t-SNE] Mean sigma: 0.830283\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 70.828308\n",
      "[t-SNE] KL divergence after 300 iterations: 1.904306\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:40.628451\n",
      "epoch num: 1\n",
      "torch.Size([6050, 1000])\n",
      "torch.Size([6050])\n",
      "0.06525109676772324\n",
      "correct 836\n",
      "incorrect 11230\n",
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 3000 samples in 0.067s...\n",
      "[t-SNE] Computed neighbors for 3000 samples in 14.111s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 3000\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 3000\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 3000\n",
      "[t-SNE] Mean sigma: 0.830283\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 70.828308\n",
      "[t-SNE] KL divergence after 300 iterations: 1.904306\n",
      "Time elapsed (hh:mm:ss.ms) 0:03:18.996417\n",
      "epoch num: 2\n",
      "torch.Size([6050, 1000])\n",
      "torch.Size([6050])\n",
      "0.04350073117848216\n",
      "correct 1254\n",
      "incorrect 16845\n",
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 3000 samples in 0.070s...\n",
      "[t-SNE] Computed neighbors for 3000 samples in 14.011s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 3000\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 3000\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 3000\n",
      "[t-SNE] Mean sigma: 0.830283\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 70.828308\n",
      "[t-SNE] KL divergence after 300 iterations: 1.904306\n",
      "Time elapsed (hh:mm:ss.ms) 0:04:57.632162\n",
      "epoch num: 3\n",
      "torch.Size([6050, 1000])\n",
      "torch.Size([6050])\n",
      "0.03262554838386162\n",
      "correct 1672\n",
      "incorrect 22460\n",
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 3000 samples in 0.072s...\n",
      "[t-SNE] Computed neighbors for 3000 samples in 14.099s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 3000\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 3000\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 3000\n",
      "[t-SNE] Mean sigma: 0.830283\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 70.828308\n",
      "[t-SNE] KL divergence after 300 iterations: 1.904306\n",
      "Time elapsed (hh:mm:ss.ms) 0:06:37.751246\n",
      "epoch num: 4\n",
      "torch.Size([6050, 1000])\n",
      "torch.Size([6050])\n",
      "0.026100438707089297\n",
      "correct 2090\n",
      "incorrect 28075\n",
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 3000 samples in 0.080s...\n",
      "[t-SNE] Computed neighbors for 3000 samples in 14.497s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 3000\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 3000\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 3000\n",
      "[t-SNE] Mean sigma: 0.830283\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 70.828308\n",
      "[t-SNE] KL divergence after 300 iterations: 1.904306\n",
      "Time elapsed (hh:mm:ss.ms) 0:08:16.376685\n",
      "epoch num: 5\n",
      "torch.Size([6050, 1000])\n",
      "torch.Size([6050])\n",
      "0.02175036558924108\n",
      "correct 2508\n",
      "incorrect 33690\n",
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 3000 samples in 0.069s...\n",
      "[t-SNE] Computed neighbors for 3000 samples in 14.224s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 3000\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 3000\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 3000\n",
      "[t-SNE] Mean sigma: 0.830283\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 70.828308\n",
      "[t-SNE] KL divergence after 300 iterations: 1.904306\n",
      "Time elapsed (hh:mm:ss.ms) 0:09:56.164651\n",
      "epoch num: 6\n",
      "torch.Size([6050, 1000])\n",
      "torch.Size([6050])\n",
      "0.018643170505063783\n",
      "correct 2926\n",
      "incorrect 39305\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-a08da2a4ff07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-83db161e2de8>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"incorrect\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincorrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mmap_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"outfile\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-666b3f236016>\u001b[0m in \u001b[0;36mmap_features\u001b[0;34m(outputs, labels, out_file)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdata_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mpca_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtsne_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.7/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \"\"\"\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.7/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'arpack'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'randomized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             raise ValueError(\"Unrecognized svd_solver='{0}'\"\n",
      "\u001b[0;32m/usr/lib64/python3.7/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36m_fit_truncated\u001b[0;34m(self, X, n_components, svd_solver)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Get variance explained by singular values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m         \u001b[0mtotal_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvar\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mvar\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m   3504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3505\u001b[0m     return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[0;32m-> 3506\u001b[0;31m                          **kwargs)\n\u001b[0m\u001b[1;32m   3507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;31m# Note that if dtype is not of inexact type then arraymean will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# not be either.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0marrmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         arrmean = um.true_divide(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run Script\n",
    "model.to(device)\n",
    "\n",
    "trained_model, loss = train_model()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
